## üß† Projeto de Redes Neurais
### Amostra Cient√≠fica CESUCA 2024

<p>
1. Voc√™ precisar√° ter instalado em sua m√°quina o Ollama e tamb√©m o modelo Llama3, certifique-se de que est√° tudo certo antes de come√ßar!

  1.1 Ap√≥s o download e rodar o Llama3 pelo Ollama, voc√™ pode certificar-se de que est√° tudo correto ao acessar o localhost na porta 11434 (porta padr√£o usada do Ollama) e l√° voc√™ ver√° uma mensagem escrito "Ollama is running".

2. Preparando o ambiente:
  Para deixar tudo certinho e rodar normalmente, utilize os seguintes comandos enquanto est√° no diret√≥rio do projeto:
    -> pip install -r requirements.txt
    -> npm init
    -> npm i express axios

3. <strong>Para rodar o app: </strong>streamlit run app.py
  <strong>Caso tenha problemas: </strong>python -m streamlit run app.py

  e lembre-se de executar o server.js via node para que a AI funcione!
  
  Portanto rode no terminal:
  node server.js

</p>

<p>projeto em constru√ß√£o...</p>