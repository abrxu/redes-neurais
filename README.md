
# ğŸ§  Projeto de Redes Neurais  
### Amostra CientÃ­fica CESUCA 2024

Bem-vindo ao projeto de redes neurais para a Amostra CientÃ­fica CESUCA 2024! Este guia ajudarÃ¡ vocÃª a configurar e executar o projeto de maneira eficiente. Certifique-se de seguir as etapas cuidadosamente para evitar problemas de configuraÃ§Ã£o.

---

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, vocÃª precisarÃ¡:

1. **Ollama**: Instale o **Ollama** em sua mÃ¡quina.
2. **Modelo Llama3**: Baixe o modelo **Llama3** pelo Ollama.

Verifique que o Ollama e o Llama3 estÃ£o funcionando corretamente acessando `localhost:11434` no navegador. VocÃª deve ver a mensagem: **"Ollama is running"**.

---

## âš™ï¸ Preparando o Ambiente

Para configurar o ambiente, siga as instruÃ§Ãµes abaixo enquanto estiver no diretÃ³rio do projeto:

```bash
# Instalar as dependÃªncias do Python
pip install -r requirements.txt

# Inicializar e instalar pacotes Node.js
npm init -y
npm install express axios
```

---

## ğŸš€ Executando o Projeto

1. **Iniciar a aplicaÃ§Ã£o Streamlit**: Execute o seguinte comando no terminal:

    ```bash
    streamlit run app.py
    ```

    Caso encontre algum problema ao executar o Streamlit, use o comando alternativo:

    ```bash
    python -m streamlit run app.py
    ```

2. **Executar o servidor para a IA**: Para que a IA funcione corretamente, inicie o `server.js` com o comando:

    ```bash
    node server.js
    ```

---

## ğŸ’» Estrutura do Projeto

Este projeto Ã© organizado da seguinte forma:

- **src/**: ContÃ©m os scripts de processamento e modelos da IA.
- **data/**: DiretÃ³rio para armazenar dados e datasets necessÃ¡rios.
- **models/**: Armazena os modelos treinados.
- **app.py**: Interface do usuÃ¡rio com Streamlit.
- **server.js**: Servidor para comunicaÃ§Ã£o com o modelo de IA via API.

---

## ğŸ› ï¸ Em ConstruÃ§Ã£o

Este projeto estÃ¡ em constante desenvolvimento. Fique atento para novas atualizaÃ§Ãµes e melhorias!
